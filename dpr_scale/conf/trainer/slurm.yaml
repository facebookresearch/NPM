# @package _global_
defaults:
  - override /hydra/launcher: submitit_slurm

trainer:
  gpus: 8
  num_nodes: 1
  max_epochs: 25
  num_sanity_val_steps: 0
  log_every_n_steps: 10
  gradient_clip_val: 2.0
  accumulate_grad_batches: 1
  strategy: ddp_sharded
  precision: 16

hydra:
  launcher:
    gpus_per_node: ${trainer.gpus}
    tasks_per_node: ${trainer.gpus}
    nodes: ${trainer.num_nodes}
    timeout_min: 4260
    cpus_per_task: 10
    mem_gb: 256
    constraint: volta32gb
    partition: learnlab
  sweep:
    dir: /checkpoint/${env:USER}/hydra_outputs/${hydra.launcher.name}/${now:%Y-%m-%d-%H%M%S}
